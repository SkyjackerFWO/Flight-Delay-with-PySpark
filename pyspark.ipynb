{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhndd/miniconda3/envs/pyspark_env/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pyspark as ps \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "import pyspark.sql.functions as pf\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import (\n",
    "    MulticlassClassificationEvaluator,\n",
    "    BinaryClassificationEvaluator,\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StringType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_delay</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DestState</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DistanceGroup</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>AirTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>TX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>5</td>\n",
       "      <td>159.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>CLT</td>\n",
       "      <td>NC</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635585</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CO</td>\n",
       "      <td>1440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635586</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GA</td>\n",
       "      <td>1420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635587</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CA</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>8</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635588</th>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635589</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CO</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635590 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         is_delay  Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "0               1  2014        1      1           1          3  2014-01-01   \n",
       "1               0  2014        1      1           1          3  2014-01-01   \n",
       "2               1  2014        1      1           1          3  2014-01-01   \n",
       "3               1  2014        1      1           1          3  2014-01-01   \n",
       "4               0  2014        1      1           1          3  2014-01-01   \n",
       "...           ...   ...      ...    ...         ...        ...         ...   \n",
       "1635585         1  2018        4     12          31          1  2018-12-31   \n",
       "1635586         0  2018        4     12          31          1  2018-12-31   \n",
       "1635587         1  2018        4     12          31          1  2018-12-31   \n",
       "1635588         0  2018        4     12          31          1  2018-12-31   \n",
       "1635589         1  2018        4     12          31          1  2018-12-31   \n",
       "\n",
       "        Reporting_Airline Origin OriginState Dest DestState  CRSDepTime  \\\n",
       "0                      UA    LAX          CA  ORD        IL         900   \n",
       "1                      AA    IAH          TX  DFW        TX        1750   \n",
       "2                      AA    LAX          CA  ORD        IL        1240   \n",
       "3                      AA    DFW          TX  LAX        CA        1905   \n",
       "4                      AA    DFW          TX  CLT        NC        1115   \n",
       "...                   ...    ...         ...  ...       ...         ...   \n",
       "1635585                AA    DFW          TX  DEN        CO        1440   \n",
       "1635586                DL    PHX          AZ  ATL        GA        1420   \n",
       "1635587                AA    ORD          IL  SFO        CA        1700   \n",
       "1635588                AA    ORD          IL  LAX        CA         720   \n",
       "1635589                AA    DFW          TX  DEN        CO        1245   \n",
       "\n",
       "         Cancelled  Diverted  Distance  DistanceGroup  ArrDelay  \\\n",
       "0              0.0       0.0    1744.0              7      43.0   \n",
       "1              0.0       0.0     224.0              1       2.0   \n",
       "2              0.0       0.0    1744.0              7      26.0   \n",
       "3              0.0       0.0    1235.0              5     159.0   \n",
       "4              0.0       0.0     936.0              4     -13.0   \n",
       "...            ...       ...       ...            ...       ...   \n",
       "1635585        0.0       0.0     641.0              3      24.0   \n",
       "1635586        0.0       0.0    1587.0              7     -14.0   \n",
       "1635587        0.0       0.0    1846.0              8      39.0   \n",
       "1635588        0.0       0.0    1744.0              7     -10.0   \n",
       "1635589        0.0       0.0     641.0              3      19.0   \n",
       "\n",
       "         ArrDelayMinutes  AirTime  \n",
       "0                   43.0    218.0  \n",
       "1                    2.0     50.0  \n",
       "2                   26.0    220.0  \n",
       "3                  159.0    169.0  \n",
       "4                    0.0    108.0  \n",
       "...                  ...      ...  \n",
       "1635585             24.0    100.0  \n",
       "1635586              0.0    179.0  \n",
       "1635587             39.0    272.0  \n",
       "1635588              0.0    240.0  \n",
       "1635589             19.0     93.0  \n",
       "\n",
       "[1635590 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('flight_delay_predict.csv')\n",
    "df['is_delay'] = df['is_delay'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:41:28 WARN Utils: Your hostname, pail resolves to a loopback address: 127.0.1.1; using 10.20.34.13 instead (on interface enp68s0)\n",
      "24/07/03 11:41:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/03 11:41:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "SparkSession.builder\n",
    ".appName(\"Flight_Delay\")\n",
    ".config(\"spark.dynamicAllocation.enabled\", True)\n",
    ".config(\"spark.dynamicAllocation.minExecutors\", 5)\n",
    ".config(\"spark.dynamicAllocation.maxExecutors\", 20)\n",
    ".config(\"spark.executor.cores\", 1)\n",
    ".config(\"spark.executor.instances\", 18)\n",
    ".config(\"spark.driver.memory\", \"10g\")\n",
    ".config(\"spark.executor.memory\", \"4g\")\n",
    ".config(\"spark.sql.execution.arrow.pyspark.enabled\", True)\n",
    ".config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    ".config(\"spark.memory.offHeap.size\", \"10g\")\n",
    ".getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('flight_delay_predict.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# spark_df = df.to_spark()\n",
    "spark_df = df.dropna()\n",
    "\n",
    "\n",
    "categorical_columns = [\"Reporting_Airline\", \"Origin\", \"OriginState\", \"Dest\", \"DestState\"]\n",
    "\n",
    "# dropping datetime columns\n",
    "date_cols = [\n",
    "    field.name\n",
    "    for field in spark_df.schema.fields\n",
    "    if isinstance(field.dataType, (DateType))\n",
    "]\n",
    "\n",
    "\n",
    "spark_df = spark_df.drop(*date_cols)\n",
    "\n",
    "# dropping the ArrDelay and ArrDelayMinutes columns\n",
    "spark_df = spark_df.drop(\"ArrDelay\", \"ArrDelayMinutes\")\n",
    "\n",
    "\n",
    "\n",
    "# encoding categorical columns\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_idx\").fit(spark_df)\n",
    "    for column in categorical_columns\n",
    "]\n",
    "\n",
    "for idx in indexers:\n",
    "    spark_df = idx.transform(spark_df)\n",
    "\n",
    "\n",
    "# dropping the original string columns\n",
    "\n",
    "string_cols = [\n",
    "    field.name\n",
    "    for field in spark_df.schema.fields\n",
    "    if isinstance(field.dataType, (StringType))\n",
    "]\n",
    "\n",
    "spark_df = spark_df.drop(*string_cols)\n",
    "\n",
    "# assembling all numerical columns into 1 vector\n",
    "\n",
    "numerical_columns = [col for col in spark_df.columns if col != \"is_delay\"]\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col + \"_idx\" for col in categorical_columns] + numerical_columns,\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "\n",
    "\n",
    "spark_df = assembler.transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:41:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(is_delay=1.0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=900, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=218.0, Reporting_Airline_idx=1.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([1.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 900.0, 0.0, 0.0, 1744.0, 7.0, 218.0, 1.0, 0.0, 0.0, 1.0, 2.0])),\n",
       " Row(is_delay=0.0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1750, Cancelled=0.0, Diverted=0.0, Distance=224.0, DistanceGroup=1, AirTime=50.0, Reporting_Airline_idx=0.0, Origin_idx=7.0, OriginState_idx=1.0, Dest_idx=3.0, DestState_idx=1.0, features=DenseVector([0.0, 7.0, 1.0, 3.0, 1.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1750.0, 0.0, 0.0, 224.0, 1.0, 50.0, 0.0, 7.0, 1.0, 3.0, 1.0])),\n",
       " Row(is_delay=1.0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1240, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=220.0, Reporting_Airline_idx=0.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([0.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1240.0, 0.0, 0.0, 1744.0, 7.0, 220.0, 0.0, 0.0, 0.0, 1.0, 2.0])),\n",
       " Row(is_delay=1.0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1905, Cancelled=0.0, Diverted=0.0, Distance=1235.0, DistanceGroup=5, AirTime=169.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=0.0, DestState_idx=0.0, features=DenseVector([0.0, 2.0, 1.0, 0.0, 0.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1905.0, 0.0, 0.0, 1235.0, 5.0, 169.0, 0.0, 2.0, 1.0, 0.0, 0.0])),\n",
       " Row(is_delay=0.0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1115, Cancelled=0.0, Diverted=0.0, Distance=936.0, DistanceGroup=4, AirTime=108.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=8.0, DestState_idx=6.0, features=DenseVector([0.0, 2.0, 1.0, 8.0, 6.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1115.0, 0.0, 0.0, 936.0, 4.0, 108.0, 0.0, 2.0, 1.0, 8.0, 6.0]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"is_delay\", col('is_delay').cast('integer')) # cast label column to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=900, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=218.0, Reporting_Airline_idx=1.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([1.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 900.0, 0.0, 0.0, 1744.0, 7.0, 218.0, 1.0, 0.0, 0.0, 1.0, 2.0])),\n",
       " Row(is_delay=0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1750, Cancelled=0.0, Diverted=0.0, Distance=224.0, DistanceGroup=1, AirTime=50.0, Reporting_Airline_idx=0.0, Origin_idx=7.0, OriginState_idx=1.0, Dest_idx=3.0, DestState_idx=1.0, features=DenseVector([0.0, 7.0, 1.0, 3.0, 1.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1750.0, 0.0, 0.0, 224.0, 1.0, 50.0, 0.0, 7.0, 1.0, 3.0, 1.0])),\n",
       " Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1240, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=220.0, Reporting_Airline_idx=0.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([0.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1240.0, 0.0, 0.0, 1744.0, 7.0, 220.0, 0.0, 0.0, 0.0, 1.0, 2.0])),\n",
       " Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1905, Cancelled=0.0, Diverted=0.0, Distance=1235.0, DistanceGroup=5, AirTime=169.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=0.0, DestState_idx=0.0, features=DenseVector([0.0, 2.0, 1.0, 0.0, 0.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1905.0, 0.0, 0.0, 1235.0, 5.0, 169.0, 0.0, 2.0, 1.0, 0.0, 0.0])),\n",
       " Row(is_delay=0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1115, Cancelled=0.0, Diverted=0.0, Distance=936.0, DistanceGroup=4, AirTime=108.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=8.0, DestState_idx=6.0, features=DenseVector([0.0, 2.0, 1.0, 8.0, 6.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1115.0, 0.0, 0.0, 936.0, 4.0, 108.0, 0.0, 2.0, 1.0, 8.0, 6.0]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "scaler = scaler.fit(spark_df)\n",
    "scaled_df = scaler.transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=900, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=218.0, Reporting_Airline_idx=1.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([1.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 900.0, 0.0, 0.0, 1744.0, 7.0, 218.0, 1.0, 0.0, 0.0, 1.0, 2.0]), scaled_features=DenseVector([0.8252, 0.0, 0.0, 0.4043, 1.0347, 1461.0425, 0.9039, 0.2939, 0.1139, 1.5081, 1.8035, 0.0, 0.0, 3.2409, 3.2656, 3.435, 0.8252, 0.0, 0.0, 0.4043, 1.0347])),\n",
       " Row(is_delay=0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1750, Cancelled=0.0, Diverted=0.0, Distance=224.0, DistanceGroup=1, AirTime=50.0, Reporting_Airline_idx=0.0, Origin_idx=7.0, OriginState_idx=1.0, Dest_idx=3.0, DestState_idx=1.0, features=DenseVector([0.0, 7.0, 1.0, 3.0, 1.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1750.0, 0.0, 0.0, 224.0, 1.0, 50.0, 0.0, 7.0, 1.0, 3.0, 1.0]), scaled_features=DenseVector([0.0, 2.8321, 0.5172, 1.2129, 0.5173, 1461.0425, 0.9039, 0.2939, 0.1139, 1.5081, 3.5069, 0.0, 0.0, 0.4163, 0.4665, 0.7878, 0.0, 2.8321, 0.5172, 1.2129, 0.5173])),\n",
       " Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1240, Cancelled=0.0, Diverted=0.0, Distance=1744.0, DistanceGroup=7, AirTime=220.0, Reporting_Airline_idx=0.0, Origin_idx=0.0, OriginState_idx=0.0, Dest_idx=1.0, DestState_idx=2.0, features=DenseVector([0.0, 0.0, 0.0, 1.0, 2.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1240.0, 0.0, 0.0, 1744.0, 7.0, 220.0, 0.0, 0.0, 0.0, 1.0, 2.0]), scaled_features=DenseVector([0.0, 0.0, 0.0, 0.4043, 1.0347, 1461.0425, 0.9039, 0.2939, 0.1139, 1.5081, 2.4849, 0.0, 0.0, 3.2409, 3.2656, 3.4665, 0.0, 0.0, 0.0, 0.4043, 1.0347])),\n",
       " Row(is_delay=1, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1905, Cancelled=0.0, Diverted=0.0, Distance=1235.0, DistanceGroup=5, AirTime=169.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=0.0, DestState_idx=0.0, features=DenseVector([0.0, 2.0, 1.0, 0.0, 0.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1905.0, 0.0, 0.0, 1235.0, 5.0, 169.0, 0.0, 2.0, 1.0, 0.0, 0.0]), scaled_features=DenseVector([0.0, 0.8092, 0.5172, 0.0, 0.0, 1461.0425, 0.9039, 0.2939, 0.1139, 1.5081, 3.8175, 0.0, 0.0, 2.295, 2.3326, 2.6629, 0.0, 0.8092, 0.5172, 0.0, 0.0])),\n",
       " Row(is_delay=0, Year=2014, Quarter=1, Month=1, DayofMonth=1, DayOfWeek=3, CRSDepTime=1115, Cancelled=0.0, Diverted=0.0, Distance=936.0, DistanceGroup=4, AirTime=108.0, Reporting_Airline_idx=0.0, Origin_idx=2.0, OriginState_idx=1.0, Dest_idx=8.0, DestState_idx=6.0, features=DenseVector([0.0, 2.0, 1.0, 8.0, 6.0, 2014.0, 1.0, 1.0, 1.0, 3.0, 1115.0, 0.0, 0.0, 936.0, 4.0, 108.0, 0.0, 2.0, 1.0, 8.0, 6.0]), scaled_features=DenseVector([0.0, 0.8092, 0.5172, 3.2344, 3.104, 1461.0425, 0.9039, 0.2939, 0.1139, 1.5081, 2.2344, 0.0, 0.0, 1.7394, 1.8661, 1.7017, 0.0, 0.8092, 0.5172, 3.2344, 3.104]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = scaled_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='is_delay', metricName='weightedFMeasure', beta=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:41:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+-----+----------+---------+----------+---------+--------+--------+-------------+-------+---------------------+----------+---------------+--------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|is_delay|Year|Quarter|Month|DayofMonth|DayOfWeek|CRSDepTime|Cancelled|Diverted|Distance|DistanceGroup|AirTime|Reporting_Airline_idx|Origin_idx|OriginState_idx|Dest_idx|DestState_idx|            features|     scaled_features|       rawPrediction|         probability|prediction|\n",
      "+--------+----+-------+-----+----------+---------+----------+---------+--------+--------+-------------+-------+---------------------+----------+---------------+--------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|2014|      1|    1|         1|        3|        59|      0.0|     0.0|  1199.0|            5|  135.0|                  2.0|       5.0|            4.0|     4.0|          3.0|[2.0,5.0,4.0,4.0,...|[1.65049274553222...|[2.82689192219038...|[0.94411183152679...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       531|      0.0|     0.0|  1379.0|            6|  169.0|                  1.0|       0.0|            0.0|     7.0|          1.0|[1.0,0.0,0.0,7.0,...|[0.82524637276611...|[1.82269289015657...|[0.86088893886316...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       545|      0.0|     0.0|   802.0|            4|  101.0|                  0.0|       2.0|            1.0|     1.0|          2.0|[0.0,2.0,1.0,1.0,...|[0.0,0.8091574975...|[1.78637518830269...|[0.85648228878870...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       555|      0.0|     0.0|  1846.0|            8|  217.0|                  0.0|       3.0|            0.0|     1.0|          2.0|[0.0,3.0,0.0,1.0,...|[0.0,1.2137362463...|[1.99724484624469...|[0.88050750087883...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       600|      0.0|     0.0|  1440.0|            6|  171.0|                  1.0|       6.0|            5.0|     1.0|          2.0|[1.0,6.0,5.0,1.0,...|[0.82524637276611...|[2.32294029632134...|[0.91075920756143...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       610|      0.0|     0.0|  2139.0|            9|  237.0|                  2.0|       3.0|            0.0|     4.0|          3.0|[2.0,3.0,0.0,4.0,...|[1.65049274553222...|[2.40274015585895...|[0.91703601557287...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       625|      0.0|     0.0|  1199.0|            5|  137.0|                  2.0|       5.0|            4.0|     4.0|          3.0|[2.0,5.0,4.0,4.0,...|[1.65049274553222...|[2.41875265355783...|[0.91824615488665...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       635|      0.0|     0.0|   651.0|            3|   99.0|                  4.0|       6.0|            5.0|     2.0|          0.0|[4.0,6.0,5.0,2.0,...|[3.30098549106444...|[1.50729058708878...|[0.81865932483143...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       705|      0.0|     0.0|   337.0|            2|   52.0|                  0.0|       3.0|            0.0|     0.0|          0.0|(21,[1,5,6,7,8,9,...|(21,[1,5,6,7,8,9,...|[1.44136402124792...|[0.80866578907538...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       705|      0.0|     0.0|   370.0|            2|   61.0|                  4.0|       6.0|            5.0|     0.0|          0.0|[4.0,6.0,5.0,0.0,...|[3.30098549106444...|[1.52625619584061...|[0.82145789048823...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       707|      0.0|     0.0|   606.0|            3|  103.0|                  1.0|       4.0|            3.0|     1.0|          2.0|[1.0,4.0,3.0,1.0,...|[0.82524637276611...|[1.16193869887423...|[0.76168480803646...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       710|      0.0|     0.0|   731.0|            3|   86.0|                  2.0|       2.0|            1.0|     4.0|          3.0|[2.0,2.0,1.0,4.0,...|[1.65049274553222...|[2.03433158471466...|[0.88435481313265...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       711|      0.0|     0.0|  1379.0|            6|  170.0|                  1.0|       0.0|            0.0|     7.0|          1.0|[1.0,0.0,0.0,7.0,...|[0.82524637276611...|[1.68289516486595...|[0.84328751817874...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       715|      0.0|     0.0|  1846.0|            8|  216.0|                  1.0|       3.0|            0.0|     1.0|          2.0|[1.0,3.0,0.0,1.0,...|[0.82524637276611...|[1.88224854482632...|[0.86786918553022...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       725|      0.0|     0.0|  1635.0|            7|  216.0|                  1.0|       7.0|            1.0|     2.0|          0.0|[1.0,7.0,1.0,2.0,...|[0.82524637276611...|[1.32807608033859...|[0.79052221784341...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       750|      0.0|     0.0|   802.0|            4|  105.0|                  0.0|       2.0|            1.0|     1.0|          2.0|[0.0,2.0,1.0,1.0,...|[0.0,0.8091574975...|[1.54854383226837...|[0.82470331646053...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       810|      0.0|     0.0|  1235.0|            5|  159.0|                  0.0|       2.0|            1.0|     0.0|          0.0|[0.0,2.0,1.0,0.0,...|[0.0,0.8091574975...|[1.55562276288884...|[0.82572435041353...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       850|      0.0|     0.0|   337.0|            2|   58.0|                  3.0|       0.0|            0.0|     2.0|          0.0|[3.0,0.0,0.0,2.0,...|[2.47573911829833...|[1.03834564666325...|[0.73853067138209...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       910|      0.0|     0.0|  1235.0|            5|  165.0|                  0.0|       2.0|            1.0|     0.0|          0.0|[0.0,2.0,1.0,0.0,...|[0.0,0.8091574975...|[1.32835554556379...|[0.79056849264447...|       0.0|\n",
      "|       0|2014|      1|    1|         1|        3|       916|      0.0|     0.0|  1635.0|            7|  195.0|                  1.0|       3.0|            0.0|     7.0|          1.0|[1.0,3.0,0.0,7.0,...|[0.82524637276611...|[1.76275103706869...|[0.85355387347131...|       0.0|\n",
      "+--------+----+-------+-----+----------+---------+----------+---------+--------+--------+-------------+-------+---------------------+----------+---------------+--------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:================================================>      (29 + 4) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-Beta measure for Logistic Regression:  0.754712023961489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"is_delay\")\n",
    "lr_model = lr.fit(train_df)\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "print(lr_predictions)\n",
    "lr_fbeta = evaluator.evaluate(lr_predictions)\n",
    "print(f\"f-Beta measure for Logistic Regression: \", lr_fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:===================================================>   (31 + 2) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-Beta measure for Random Forest:  0.7503046353317645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"is_delay\")\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "rf_fbeta = evaluator.evaluate(rf_predictions)\n",
    "print(f\"f-Beta measure for Random Forest: \", rf_fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol='is_delay', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest:  0.7901566022826774\n",
      "Accuracy for Logistic Regression:  0.7927529113136226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy for Random Forest: \", acc_evaluator.evaluate(rf_predictions))\n",
    "print(\"Accuracy for Logistic Regression: \", acc_evaluator.evaluate(lr_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(rf.numTrees, [10, 20, 30]).\\\n",
    "    addGrid(rf.maxDepth, [5, 10, 15]).\\\n",
    "    addGrid(rf.minInfoGain, [0.0, 0.1, 0.2]).\\\n",
    "    build()\n",
    "    \n",
    "lr_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(lr.regParam, [0.0, 0.1, 0.2]).\\\n",
    "    addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]).\\\n",
    "    addGrid(lr.fitIntercept, [False, True]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:42:25 WARN DAGScheduler: Broadcasting large task binary with size 1517.9 KiB\n",
      "24/07/03 11:42:30 WARN DAGScheduler: Broadcasting large task binary with size 1517.9 KiB\n",
      "24/07/03 11:42:30 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/07/03 11:42:31 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/07/03 11:42:32 WARN DAGScheduler: Broadcasting large task binary with size 1118.7 KiB\n",
      "24/07/03 11:42:32 WARN DAGScheduler: Broadcasting large task binary with size 7.6 MiB\n",
      "24/07/03 11:42:33 WARN DAGScheduler: Broadcasting large task binary with size 1777.6 KiB\n",
      "24/07/03 11:42:34 WARN DAGScheduler: Broadcasting large task binary with size 12.3 MiB\n",
      "24/07/03 11:42:36 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/07/03 11:42:38 WARN DAGScheduler: Broadcasting large task binary with size 19.1 MiB\n",
      "24/07/03 11:42:40 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/07/03 11:42:41 WARN DAGScheduler: Broadcasting large task binary with size 9.3 MiB\n",
      "24/07/03 11:42:50 WARN DAGScheduler: Broadcasting large task binary with size 1594.4 KiB\n",
      "24/07/03 11:42:51 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:42:52 WARN DAGScheduler: Broadcasting large task binary with size 1266.7 KiB\n",
      "24/07/03 11:42:56 WARN DAGScheduler: Broadcasting large task binary with size 1594.4 KiB\n",
      "24/07/03 11:42:57 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:42:58 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "24/07/03 11:42:59 WARN DAGScheduler: Broadcasting large task binary with size 1350.5 KiB\n",
      "24/07/03 11:43:00 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "24/07/03 11:43:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/07/03 11:43:03 WARN DAGScheduler: Broadcasting large task binary with size 15.0 MiB\n",
      "24/07/03 11:43:05 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/07/03 11:43:07 WARN DAGScheduler: Broadcasting large task binary with size 24.5 MiB\n",
      "24/07/03 11:43:10 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "24/07/03 11:43:14 WARN DAGScheduler: Broadcasting large task binary with size 38.3 MiB\n",
      "24/07/03 11:43:18 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:43:21 WARN DAGScheduler: Broadcasting large task binary with size 18.3 MiB\n",
      "24/07/03 11:43:32 WARN DAGScheduler: Broadcasting large task binary with size 1267.9 KiB\n",
      "24/07/03 11:43:33 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/07/03 11:43:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:43:35 WARN DAGScheduler: Broadcasting large task binary with size 1148.5 KiB\n",
      "24/07/03 11:43:35 WARN DAGScheduler: Broadcasting large task binary with size 1811.4 KiB\n",
      "24/07/03 11:43:41 WARN DAGScheduler: Broadcasting large task binary with size 1267.9 KiB\n",
      "24/07/03 11:43:41 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/07/03 11:43:43 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:43:44 WARN DAGScheduler: Broadcasting large task binary with size 1148.5 KiB\n",
      "24/07/03 11:43:44 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:43:46 WARN DAGScheduler: Broadcasting large task binary with size 2018.0 KiB\n",
      "24/07/03 11:43:47 WARN DAGScheduler: Broadcasting large task binary with size 13.2 MiB\n",
      "24/07/03 11:43:49 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/07/03 11:43:51 WARN DAGScheduler: Broadcasting large task binary with size 22.3 MiB\n",
      "24/07/03 11:43:55 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "24/07/03 11:43:58 WARN DAGScheduler: Broadcasting large task binary with size 36.5 MiB\n",
      "24/07/03 11:44:03 WARN DAGScheduler: Broadcasting large task binary with size 7.9 MiB\n",
      "24/07/03 11:44:08 WARN DAGScheduler: Broadcasting large task binary with size 57.0 MiB\n",
      "24/07/03 11:44:15 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/07/03 11:44:19 WARN DAGScheduler: Broadcasting large task binary with size 27.1 MiB\n",
      "24/07/03 11:44:34 WARN DAGScheduler: Broadcasting large task binary with size 1507.5 KiB\n",
      "24/07/03 11:44:39 WARN DAGScheduler: Broadcasting large task binary with size 1507.5 KiB\n",
      "24/07/03 11:44:39 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/07/03 11:44:40 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/07/03 11:44:41 WARN DAGScheduler: Broadcasting large task binary with size 1121.1 KiB\n",
      "24/07/03 11:44:41 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:44:42 WARN DAGScheduler: Broadcasting large task binary with size 1784.5 KiB\n",
      "24/07/03 11:44:43 WARN DAGScheduler: Broadcasting large task binary with size 12.3 MiB\n",
      "24/07/03 11:44:45 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/07/03 11:44:46 WARN DAGScheduler: Broadcasting large task binary with size 19.2 MiB\n",
      "24/07/03 11:44:49 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "24/07/03 11:44:50 WARN DAGScheduler: Broadcasting large task binary with size 9.3 MiB\n",
      "24/07/03 11:44:58 WARN DAGScheduler: Broadcasting large task binary with size 1581.2 KiB\n",
      "24/07/03 11:44:59 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:45:00 WARN DAGScheduler: Broadcasting large task binary with size 1290.2 KiB\n",
      "24/07/03 11:45:04 WARN DAGScheduler: Broadcasting large task binary with size 1581.2 KiB\n",
      "24/07/03 11:45:05 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:45:06 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "24/07/03 11:45:07 WARN DAGScheduler: Broadcasting large task binary with size 1333.6 KiB\n",
      "24/07/03 11:45:08 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "24/07/03 11:45:09 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/07/03 11:45:11 WARN DAGScheduler: Broadcasting large task binary with size 14.9 MiB\n",
      "24/07/03 11:45:13 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/07/03 11:45:15 WARN DAGScheduler: Broadcasting large task binary with size 24.4 MiB\n",
      "24/07/03 11:45:18 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "24/07/03 11:45:22 WARN DAGScheduler: Broadcasting large task binary with size 38.2 MiB\n",
      "24/07/03 11:45:26 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:45:29 WARN DAGScheduler: Broadcasting large task binary with size 18.3 MiB\n",
      "24/07/03 11:45:39 WARN DAGScheduler: Broadcasting large task binary with size 1266.5 KiB\n",
      "24/07/03 11:45:40 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/07/03 11:45:41 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:45:42 WARN DAGScheduler: Broadcasting large task binary with size 1154.5 KiB\n",
      "24/07/03 11:45:43 WARN DAGScheduler: Broadcasting large task binary with size 1830.5 KiB\n",
      "24/07/03 11:45:48 WARN DAGScheduler: Broadcasting large task binary with size 1266.5 KiB\n",
      "24/07/03 11:45:49 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/07/03 11:45:50 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:45:51 WARN DAGScheduler: Broadcasting large task binary with size 1154.5 KiB\n",
      "24/07/03 11:45:52 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:45:53 WARN DAGScheduler: Broadcasting large task binary with size 2045.0 KiB\n",
      "24/07/03 11:45:54 WARN DAGScheduler: Broadcasting large task binary with size 13.3 MiB\n",
      "24/07/03 11:45:57 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "24/07/03 11:45:59 WARN DAGScheduler: Broadcasting large task binary with size 22.6 MiB\n",
      "24/07/03 11:46:02 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "24/07/03 11:46:06 WARN DAGScheduler: Broadcasting large task binary with size 36.9 MiB\n",
      "24/07/03 11:46:11 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "24/07/03 11:46:17 WARN DAGScheduler: Broadcasting large task binary with size 57.8 MiB\n",
      "24/07/03 11:46:24 WARN DAGScheduler: Broadcasting large task binary with size 11.4 MiB\n",
      "24/07/03 11:46:29 WARN DAGScheduler: Broadcasting large task binary with size 27.6 MiB\n",
      "24/07/03 11:46:45 WARN DAGScheduler: Broadcasting large task binary with size 1492.7 KiB\n",
      "24/07/03 11:46:49 WARN DAGScheduler: Broadcasting large task binary with size 1492.7 KiB\n",
      "24/07/03 11:46:50 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/07/03 11:46:50 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "24/07/03 11:46:51 WARN DAGScheduler: Broadcasting large task binary with size 1085.8 KiB\n",
      "24/07/03 11:46:51 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n",
      "24/07/03 11:46:52 WARN DAGScheduler: Broadcasting large task binary with size 1724.8 KiB\n",
      "24/07/03 11:46:54 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n",
      "24/07/03 11:46:55 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/07/03 11:46:57 WARN DAGScheduler: Broadcasting large task binary with size 18.6 MiB\n",
      "24/07/03 11:46:59 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "24/07/03 11:47:00 WARN DAGScheduler: Broadcasting large task binary with size 9.1 MiB\n",
      "24/07/03 11:47:10 WARN DAGScheduler: Broadcasting large task binary with size 1588.3 KiB\n",
      "24/07/03 11:47:11 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:47:12 WARN DAGScheduler: Broadcasting large task binary with size 1280.7 KiB\n",
      "24/07/03 11:47:17 WARN DAGScheduler: Broadcasting large task binary with size 1588.3 KiB\n",
      "24/07/03 11:47:18 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:47:19 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "24/07/03 11:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1339.2 KiB\n",
      "24/07/03 11:47:21 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "24/07/03 11:47:22 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/07/03 11:47:23 WARN DAGScheduler: Broadcasting large task binary with size 15.0 MiB\n",
      "24/07/03 11:47:26 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "24/07/03 11:47:28 WARN DAGScheduler: Broadcasting large task binary with size 24.4 MiB\n",
      "24/07/03 11:47:31 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "24/07/03 11:47:35 WARN DAGScheduler: Broadcasting large task binary with size 38.2 MiB\n",
      "24/07/03 11:47:39 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "24/07/03 11:47:42 WARN DAGScheduler: Broadcasting large task binary with size 18.4 MiB\n",
      "24/07/03 11:47:53 WARN DAGScheduler: Broadcasting large task binary with size 1259.1 KiB\n",
      "24/07/03 11:47:53 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/07/03 11:47:55 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:47:56 WARN DAGScheduler: Broadcasting large task binary with size 1123.0 KiB\n",
      "24/07/03 11:47:56 WARN DAGScheduler: Broadcasting large task binary with size 1778.5 KiB\n",
      "24/07/03 11:48:01 WARN DAGScheduler: Broadcasting large task binary with size 1259.1 KiB\n",
      "24/07/03 11:48:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/07/03 11:48:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:48:04 WARN DAGScheduler: Broadcasting large task binary with size 1123.0 KiB\n",
      "24/07/03 11:48:05 WARN DAGScheduler: Broadcasting large task binary with size 7.3 MiB\n",
      "24/07/03 11:48:07 WARN DAGScheduler: Broadcasting large task binary with size 1972.6 KiB\n",
      "24/07/03 11:48:08 WARN DAGScheduler: Broadcasting large task binary with size 12.9 MiB\n",
      "24/07/03 11:48:10 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "24/07/03 11:48:12 WARN DAGScheduler: Broadcasting large task binary with size 21.9 MiB\n",
      "24/07/03 11:48:15 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "24/07/03 11:48:19 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "24/07/03 11:48:24 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "24/07/03 11:48:31 WARN DAGScheduler: Broadcasting large task binary with size 56.4 MiB\n",
      "24/07/03 11:48:38 WARN DAGScheduler: Broadcasting large task binary with size 11.1 MiB\n",
      "24/07/03 11:48:43 WARN DAGScheduler: Broadcasting large task binary with size 26.9 MiB\n",
      "24/07/03 11:48:55 WARN DAGScheduler: Broadcasting large task binary with size 1489.5 KiB\n",
      "24/07/03 11:48:55 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/07/03 11:48:56 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "24/07/03 11:48:57 WARN DAGScheduler: Broadcasting large task binary with size 1156.3 KiB\n",
      "24/07/03 11:48:57 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "24/07/03 11:48:58 WARN DAGScheduler: Broadcasting large task binary with size 1881.4 KiB\n",
      "24/07/03 11:49:00 WARN DAGScheduler: Broadcasting large task binary with size 12.7 MiB\n",
      "24/07/03 11:49:01 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "24/07/03 11:49:03 WARN DAGScheduler: Broadcasting large task binary with size 20.2 MiB\n",
      "24/07/03 11:49:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/07/03 11:49:07 WARN DAGScheduler: Broadcasting large task binary with size 9.5 MiB\n",
      "[Stage 1567:=>                                                    (1 + 32) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest after cross-validation:  0.7977533231840328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_crossval = CrossValidator(estimator=rf, estimatorParamMaps=rf_param_grid, evaluator=evaluator, numFolds=3)\n",
    "rf_cv_model = rf_crossval.fit(train_df)\n",
    "\n",
    "\n",
    "\n",
    "rf_cv_predictions = rf_cv_model.transform(test_df)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy for Random Forest after cross-validation: \", acc_evaluator.evaluate(rf_cv_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NumTrees: 10\n",
      "Best MaxDepth: 15\n",
      "Best MinInfoGain: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best NumTrees: {rf_cv_model.bestModel.getNumTrees}\")\n",
    "print(f\"Best MaxDepth: {rf_cv_model.bestModel.getMaxDepth()}\")\n",
    "print(f\"Best MinInfoGain: {rf_cv_model.bestModel.getMinInfoGain()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:52:35 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression after cross-validation:  0.7927529113136226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_crossval = CrossValidator(\n",
    "    estimator=lr, estimatorParamMaps=lr_param_grid, evaluator=evaluator, numFolds=3\n",
    ")\n",
    "lr_cv_model = lr_crossval.fit(train_df)\n",
    "\n",
    "lr_cv_predictions = lr_cv_model.transform(test_df)\n",
    "print(\n",
    "    \"Accuracy for Logistic Regression after cross-validation: \",\n",
    "    acc_evaluator.evaluate(lr_cv_predictions),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regParam: 0.0\n",
      "Best elasticNetParam: 0.0\n",
      "Fit Intercept: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best regParam: {lr_cv_model.bestModel.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {lr_cv_model.bestModel.getElasticNetParam()}\")\n",
    "print(f\"Fit Intercept: {lr_cv_model.bestModel.getFitIntercept()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:52:52 WARN DAGScheduler: Broadcasting large task binary with size 9.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f-Beta score for Random Forest 0.7636769140071639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8771:========================>                            (15 + 18) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f-Beta score for Logistic Regression 0.754712023961489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Best f-Beta score for Random Forest {evaluator.evaluate(rf_cv_predictions)}\")\n",
    "print(f\"Best f-Beta score for Logistic Regression {evaluator.evaluate(lr_cv_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import FMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FMClassifier(featuresCol=\"scaled_features\", labelCol=\"is_delay\")\n",
    "\n",
    "fm_param_grid = ParamGridBuilder().\\\n",
    "    addGrid(fm.stepSize, [0.1, 0.01, 0.001]).\\\n",
    "    addGrid(fm.maxIter, [10, 20, 30]).\\\n",
    "    addGrid(fm.regParam, [0.1, 0.01, 0.001]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fm_crossval = CrossValidator(estimator=fm, estimatorParamMaps=fm_param_grid, evaluator=evaluator, numFolds=3)\n",
    "fm_cv_model = fm_crossval.fit(train_df)\n",
    "\n",
    "fm_cv_predictions = fm_cv_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Factorization Machine after cross-validation: 0.7901566022826774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12443:=======================>                            (15 + 18) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f-Beta score for Factorization Machine: 0.7503046353317645\n",
      "Best stepSize: 0.1\n",
      "Best maxIter: 10\n",
      "Best regParam: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for Factorization Machine after cross-validation: {acc_evaluator.evaluate(fm_cv_predictions)}\")\n",
    "print(f\"Best f-Beta score for Factorization Machine: {evaluator.evaluate(fm_cv_predictions)}\")\n",
    "print(f\"Best stepSize: {fm_cv_model.bestModel.getStepSize()}\")\n",
    "print(f\"Best maxIter: {fm_cv_model.bestModel.getMaxIter()}\")\n",
    "print(f\"Best regParam: {fm_cv_model.bestModel.getRegParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
